<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="CS 639 Final Project - Robotic Throwing and Catching with UR5e Arms">
    <title>Robotic Throwing & Catching | CS 639 Final Project</title>
    <link rel="stylesheet" href="css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <script>
        window.MathJax = {
        tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
        svg: { fontCache: 'global' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>
<body>
    <!-- Navigation -->
    <nav id="navbar">
        <div class="nav-container">
            <div class="nav-brand">
                <span class="brand-icon">ü§ñ</span>
                <span class="brand-text">Robo Throw & Catch</span>
            </div>
            <ul class="nav-menu">
                <li><a href="#home" class="nav-link">Home</a></li>
                <li><a href="#overview" class="nav-link">Overview</a></li>
                <li><a href="#approach" class="nav-link">Approach</a></li>
                <li><a href="#results" class="nav-link">Results</a></li>
                <li><a href="#demo" class="nav-link">Demo</a></li>
                <li><a href="#reflection" class="nav-link">Reflection</a></li>
                <li><a href="#team" class="nav-link">Team</a></li>
                <li><a href="https://github.com/ayuan1114/robo-final-proj" target="_blank" class="nav-link github-link">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                    </svg>
                    GitHub
                </a></li>
            </ul>
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section id="home" class="hero">
        <div class="hero-background">
            <div class="hero-gradient"></div>
        </div>
        <div class="container hero-content">
            <div class="hero-text">
                <span class="hero-tag">CS 639 Final Project</span>
                <h1 class="hero-title">Robot Throwing <span class="gradient-text">&</span> "Catching"</h1>
                <p class="hero-subtitle">Demonstrating dynamic manipulation with UR5e robot arms using reinforcement learning and trajectory optimization</p>
                <div class="hero-buttons">
                    <a href="#demo" class="btn btn-primary">Watch Demo</a>
                    <a href="https://github.com/ayuan1114/robo-final-proj" target="_blank" class="btn btn-secondary">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                        </svg>
                        View Code
                    </a>
                </div>
            </div>
        </div>
        <div class="scroll-indicator">
            <span>Scroll to explore</span>
            <div class="scroll-arrow"></div>
        </div>
    </section>

    <!-- Overview Section -->
    <section id="overview" class="section">
        <div class="container">
            <div class="section-header">
                <span class="section-tag">About</span>
                <h2 class="section-title">Project Overview</h2>
                
                <!-- Abstract Paragraph -->
                <div class="abstract-box">
                    <h3 class="abstract-title">Abstract</h3>
                    <p class="abstract-text">
                        This project demonstrates dynamic manipulation through robotic throwing and catching using two UR5e arms 
                        with Robotiq 2F-85 grippers in the WeBots simulation environment. The project evolved into exploring the 
                        interplay pseudo RL and naive throwing similar to human ball-throwing dynamics. We developed two throwing 
                        strategies: a baseline human-defined controller using linear interpolation, and a learned controller optimized 
                        through Proximal Policy Optimization (PPO) with cubic spline trajectory generation. 
                        The learned controller significantly outperformed the baseline, achieving release velocities up to 3.87 m/s 
                        and horizontal distances of 1.77m compared to the baseline's 1.79 m/s and 1.57m. 
                        For catching, we implemented an adaptive interception system that performs real-time trajectory 
                        prediction using physics-based projectile motion modeling and inverse kinematics. 
                        The catcher successfully intercepts thrown blocks by dynamically computing catch planes and gripper timing 
                        based on block velocity and position. Through systematic experimentation with trajectory complexity 
                        (2-6 knots) and multiple random seeds, we demonstrated that simpler trajectories (2 knots) achieved the
                        best throwing performance, while more complex trajectories (6 knots) showed higher success rates, revealing
                        interesting trade-offs between trajectory expressiveness and learning stability in robot manipulation tasks.
                    </p>
                </div>
    
                <!-- Context -->
                <div class="context-section">
                    <h3 class="context-title">Project Context & Motivation</h3>
                    <p class="context-text">
                        Our original motivation for this project stemmed from the mechanics and idea behind various sport motions.
                        Think basketball shot blocking, dart throwing, baseball pitching and catching. These motions are so unique to humans
                        and require a lot of skill to master. We wanted to explore how robots could learn to perform similar dynamic manipulation 
                        tasks.
                        However, dynamic manipulation tasks like throwing and catching remain challenging problems in robotics, 
                        requiring precise control, accurate prediction, and real-time adaptation. Unlike quasi-static manipulation 
                        where objects move slowly and contact is maintained, dynamic manipulation involves ballistic phases where 
                        the robotic system must reason about projectile physics and timing. This project was motivated by the 
                        observation that humans are natural at such tasks through learned motor skills. Ultimately, suggesting that 
                        reinforcement learning could similarly enable robots to discover effective throwing strategies or other 
                        human-like motions. Our work demonstrates how combining learning-based trajectory optimization with 
                        physics-based prediction can achieve robust dynamic manipulation and human-like motions.
                        In the future, we see potential applications in manufacturing, sports robotics, and any human-robot interaction.
                    </p>
                </div>
            </div>
    
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">üéØ</div>
                    <h3>Precise Throwing</h3>
                    <p>Developed two throwing approaches: a baseline human-defined policy and an RL-optimized trajectory using cubic spline interpolation</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">ü§ù</div>
                    <h3>Dynamic Catching</h3>
                    <p>Real-time trajectory prediction and interception using forward kinematics and projectile motion tracking</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">üß†</div>
                    <h3>RL Training</h3>
                    <p>Reinforcement learning with PPO algorithm to optimize throwing trajectories through continuous simulation feedback</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Approach Section -->
    <section id="approach" class="section section-alt">
        <div class="container">
            <div class="section-header">
                <span class="section-tag">Methodology</span>
                <h2 class="section-title">Technical Approach</h2>
            </div>

            <div class="approach-content">
                <!-- Throwing Section -->
                <div class="approach-block">
                    <h3 class="approach-subtitle">
                        <span class="approach-number">01</span>
                        Throwing Strategy
                    </h3>
                    <div class="approach-details">
                        <div class="approach-text">
                            <h4>Baseline: Naive Controller</h4>
                            <p>
                                Implemented a human-defined throwing motion. 
                                This was simply just specifying a starting pose and ending pose and then linearly interpolating joint angles between them to generate a throwing motion.
                                Some work playing with the time between the start and end poses was done to achieve a satisfying throwing motion.
                            </p>
                            
                            <h4>Learned Controller: RL Optimization</h4>
                            <p>
                                Used <strong>Proximal Policy Optimization (PPO)</strong> to learn optimal throwing trajectories.
                                Throwing is trained through a custom simulation-in-the-loop environment built in Webots.
                                Our learned throwing policies iare defined by intermediate poses (knots) and the timestep during the throw that the block si released at.
                                The RL agent's action space consists of modifications to the poses at each knot and the release timestep.
                                We generate a trajectory using cubic spline interpolation through the start pose, knot poses, and end pose.
                                We also determine the claw opening and closing times based on the release timestep.
                                The success of the agent is determined by the reward function which we have defined below.
                            </p>
                            
                            <div class="code-block">
                                <div class="code-header">
                                    <span>Trajectory Generation</span>
                                    
                                </div>
                                <pre><code>
def _knots_to_traj(self, action, n_timesteps=30):
    # Build cubic spline through [start, knots..., end]
    cs = CubicSpline(t_pts, values, bc_type='clamped')
    q_traj[:, joint_idx] = cs(t_full)
    return q_traj
                                </code></pre>
                            </div>

                            <h4>Reward Function</h4>
                            <p>$R(\mathbf{\theta}) = 50 v_{hor} + 5 v_z + 20 d_{final} + I(success)$</p>
                            <ul class="feature-list">
                                <li>$\mathbf{\theta}$: defines the poses at each knots and the timestep within the trajectory to release the block</li>
                                <li>$\mathbf{v_{hor}}$: horizontal velocity (magnitude in the xy plane) on release</li>
                                <li>$\mathbf{v_z}$: vertical velocity (along z-axis) at release</li>
                                <li>$\mathbf{d_{final}}$: horizontal displacement when the block passes through the table's plane ($z = 0.715$)</li>
                                <li>$\mathbf{I(success)} = 1000$ if the projectile succesfully reaches the checkpoint ($x \leq -0.67$) before hitting the table's plane otherise $-100$</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Catching Section -->
                <div class="approach-block">
                    <h3 class="approach-subtitle">
                        <span class="approach-number">02</span>
                        Catching Strategy
                    </h3>
                    <div class="approach-details">
                        <div class="approach-text">
                            <h4>Trajectory Prediction</h4>
                            <p>The catcher arm tracks the thrown block's position and velocity in real-time, predicting its parabolic trajectory using physics-based motion models.</p>
                            
                            <h4>Motion Planning</h4>
                            <p>Once the trajectory is predicted, inverse kinematics (IK) is used to compute joint angles that position the gripper at the interception point. The arm moves to the predicted catch location with smooth motion planning.</p>

                            <h4>Key Components</h4>
                            <ul class="feature-list">
                                <li>Real-time position tracking using Webots Supervisor API</li>
                                <li>Forward kinematics (FK) for end-effector positioning</li>
                                <li>Inverse kinematics (IK) for joint angle computation</li>
                                <li>Gripper timing control for secure catching</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Simulation Section -->
                <div class="approach-block">
                    <h3 class="approach-subtitle">
                        <span class="approach-number">03</span>
                        Simulation Environment
                    </h3>
                    <div class="approach-details">
                        <div class="approach-text">
                            <h4>Webots Platform</h4>
                            <p>
                                Developed in <strong>Webots R2023b</strong> with headless simulation to support fast training and GUI support for debugging.
                                Webots provides accurate physics simulation with realistic joint dynamics and gripper mechanics.
                                It also enables us to get real-time state feedback about robot states and block position and velocity.
                            </p>

                            <h4>System Architecture</h4>
                            <ul class="feature-list">
                                <li><strong>Gym Environment:</strong> Custom OpenAI Gym wrapper for RL training.</li>
                                <li><strong>Simulator:</strong> Webots instance for trajectory evaluation, option for either fast headless mode or real-time GUI mode.</li>
                                <li><strong>Controllers:</strong> Separate controllers for thrower, catcher, and evaluation.</li>
                                    <ul>
                                        <li><em>Naive Thrower Controller:</em> Executes predefined throwing trajectory.</li>
                                        <li><em>Learned Thrower Controller:</em> Executes throwing trajectory based on a selected trajectory (set EVAL_TRAJ environment variable).</li>
                                        <li><em>Catcher Controller:</em> Tracks block and computes interception trajectory.</li>
                                        <li><em>Evaluator Controller:</em> Runs within an isolated Webots world that is used solely for training. Monitors block state during each episode and computes rewards.</li>
                                    </ul>
                                <li><strong>Data Pipeline:</strong> JSON-based communication between training loop and simulation</li>
                            </ul>

                            <div class="tech-stack">
                                <span class="tech-badge">Python 3.10</span>
                                <span class="tech-badge">Webots R2023b</span>
                                <span class="tech-badge">Stable-Baselines3</span>
                                <span class="tech-badge">NumPy</span>
                                <span class="tech-badge">SciPy</span>
                                <span class="tech-badge">Weights & Biases</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section id="results" class="section">
        <div class="container">
            <div class="section-header">
                <span class="section-tag">Performance</span>
                <h2 class="section-title">Training Results</h2>
                <p class="section-description">
                    RL training progress and performance metrics from the learned throwing controller
                </p>
            </div>

            <div class="approach-content">
                <div class="approach-block">
                    <h3 class="approach-subtitle">
                        <span class="approach-number">01</span>
                        Varying Knots Experiment
                    </h3>
                    <div class="approach-details">
                        <p>
                            We ran multiple training experiments with different numbers of knots (2, 3, 4, 6) to see how trajectory complexity affects training and final performance.
                            More knots allow for more complex trajectories but also increase the action space dimensionality, making learning more challenging.
                            We trained each agent using the same reward function (specified above) for 1000 steps and kept a reward seed of 42 for consistency.
                            We wanted to see which number of knots provides the best trade-off between expressiveness and learnability.
                        </p>
                    </div>
                </div>
            </div>

            <div class="results-container">

                <!-- Training Graphs -->
                <div class="graphs-section">
                    <h3 class="subsection-title">Training Progression</h3>
                    <div class="graph-grid">
                        <div class="graph-card">
                            <h4>Horizontal Velocity Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/knots_vel.png" alt="Velocity progress" class="graph-img" />
                            </div>
                        </div>
                        <div class="graph-card">
                            <h4>Final Distance Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/knots_dist.png" alt="Distance progress" class="graph-img" />
                            </div>
                        </div>
                        <div class="graph-card">
                            <h4>Reward Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/knots_reward.png" alt="Reward progress" class="graph-img" />
                            </div>
                        </div>
                        <div class="graph-card">
                            <h4>Success Rate Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/knots_success.png" alt="Success rate progress" class="graph-img" />
                            </div>
                        </div>
                    </div>
                </div>

                <h3 class="subsection-title">Average Performance Across Knots</h3>
                <div class="results-grid">
                    <!-- Metrics Cards -->
                    <div class="metric-card">
                        <div class="metric-icon">üîÑ</div>
                        <div class="metric-value" data-target="1000">0</div>
                        <div class="metric-label">Training Episodes</div>
                        <div class="metric-description">During experiments</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-icon">‚ö°</div>
                        <div class="metric-value" data-target="3.60">0</div>
                        <div class="metric-label">Avg Velocity (m/s)</div>
                        <div class="metric-description">Absolute release speed</div>
                    </div>
                    <div class="metric-card">
                        <div class="metric-icon">üéØ</div>
                        <div class="metric-value" data-target="1.02">0</div>
                        <div class="metric-label">Avg Distance (m)</div>
                        <div class="metric-description">Horizontal distance from release</div>
                    </div>
                </div>

                <!-- Comparison Table -->
                <div class="comparison-section">
                    <h3 class="subsection-title">Knots Comparison</h3>
                    <div class="comparison-table">
                        <table>
                            <thead>
                                <tr>
                                    <th>Number of Knots</th>
                                    <th>Best Policy Distance</th>
                                    <th>Best Policy Velocity</th>
                                    <th>Final Success Rate</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td><strong>Naive</strong></td>
                                    <td>1.57m</td>
                                    <td>1.79 m/s</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td><strong>2</strong></td>
                                    <td><strong>1.77m</strong></td>
                                    <td><strong>3.87 m/s</strong></td>
                                    <td>42.2%</td>
                                </tr>
                                <tr>
                                    <td><strong>3</strong></td>
                                    <td>1.65m</td>
                                    <td>3.81 m/s</td>
                                    <td>23.2%</td>
                                </tr>
                                <tr>
                                    <td><strong>4</strong></td>
                                    <td>1.65m</td>
                                    <td>3.80 m/s</td>
                                    <td>46.2%</td>
                                </tr>
                                <tr>
                                    <td><strong>6</strong></td>
                                    <td>1.62m</td>
                                    <td>2.93 m/s</td>
                                    <td><strong>59.0%</strong></td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="comparison-section">
                    <h3 class="subsection-title">Experimental Results</h3>
                    <div class="approach-text">
                        <h4>Learned vs. Naive</h4>
                        <p>
                            First off, we can see that all learned controllers were able to achieve a better release velocity and distance compared to the naive controller.
                            This significant different in velocity is likely because of the relatively strong weight for velocity in our reward function and some physics hacking discovered throw learning.
                        </p>
                        <h4>How did knots affect performance</h4>
                        <p>
                            Among the learned controllers, we can see that the 6-knots controller was able to achieve the best success rate throughout the training and seems to perform well when looking at the graphs.
                            However, we can see that the 2-knots controller was actually able to achieve the best throwing policy with the best distance and velocity across the board.
                            The overall results of this experiment also seem to show that throwing policy performance does not scale with the number of knots used.
                        </p>
                    </div>
                </div>

                <div class="approach-block" style="margin-top: 80px;">
                    <h3 class="approach-subtitle">
                        <span class="approach-number">02</span>
                        Training Performance Across Seeds
                    </h3>
                    <div class="approach-details">
                        <p>
                            After determining that the 2-knot trajectories worked best for simply getting a good throwing policy, we ran another experiment to see how training performance varied across different random seeds.
                            We ran 4 random seeds (42, 246813579, 3812978465, 1732584193)
                        </p>
                    </div>
                </div>
            </div>

            <div class="results-container">

                <!-- Training Graphs -->
                <div class="graphs-section">
                    <h3 class="subsection-title">Training Progression</h3>
                    <div class="graph-grid">
                        <div class="graph-card">
                            <h4>Horizontal Velocity Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/seeds_vel.png" alt="Velocity progress" class="graph-img" />
                            </div>
                        </div>
                        <div class="graph-card">
                            <h4>Final Distance Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/seeds_dist.png" alt="Distance progress" class="graph-img" />
                            </div>
                        </div>
                        <div class="graph-card">
                            <h4>Reward Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/seeds_reward.png" alt="Reward progress" class="graph-img" />
                            </div>
                        </div>
                        <div class="graph-card">
                            <h4>Success Rate Progress</h4>
                            <div class="graph-wrapper">
                                <img src="assets/graphs/seeds_success.png" alt="Success rate progress" class="graph-img" />
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Demo Video Section -->
    <section id="demo" class="section section-alt">
        <div class="container">
            <div class="section-header">
                <span class="section-tag">Demonstration</span>
                <h2 class="section-title">Live Demo</h2>
                <p class="section-description">
                    Watch our robot system in action - comparing naive and learned throwing approaches
                </p>
            </div>

            <div class="demo-container">
                <!-- Naive Throw Video -->
                <div class="demo-video-section">
                    <h3 class="demo-video-title">Naive Throw</h3>
                    <div class="video-wrapper">
                        <iframe 
                            src="https://www.youtube.com/embed/zNUaodvrQoY?rel=0" 
                            title="Robot Naive Throwing Demo" 
                            frameborder="0" 
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
                            allowfullscreen>
                        </iframe>
                    </div>
                    <p class="demo-video-description">
                        Hard-defined throwing motion using linear interpolation between start and end poses
                    </p>
                </div>

                <!-- Learned Throw Video -->
                <div class="demo-video-section">
                    <h3 class="demo-video-title">Learned Throw</h3>
                    <div class="video-wrapper">
                        <iframe 
                            src="https://www.youtube.com/embed/bRBkdSj29nI?rel=0" 
                            title="Robot Learned Throwing Demo" 
                            frameborder="0" 
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
                            allowfullscreen>
                        </iframe>
                    </div>
                    <p class="demo-video-description">
                        Pseudo RL-optimized trajectory using PPO with cubic spline interpolation
                    </p>
                </div>
            </div>

            <div class="demo-description">
                <h3>What You'll See</h3>
                <ul class="demo-features">
                    <li>
                        <span class="demo-icon">üéØ</span>
                        <div>
                            <strong>Learned Throwing</strong>
                            <p>RL-optimized trajectory executing smooth, accurate throws</p>
                        </div>
                    </li>
                    <li>
                        <span class="demo-icon">ü§ñ</span>
                        <div>
                            <strong>Dynamic Catching</strong>
                            <p>Real-time trajectory prediction and interception</p>
                        </div>
                    </li>
                    <li>
                        <span class="demo-icon">üîÑ</span>
                        <div>
                            <strong>Complete System</strong>
                            <p>Full throwing and catching cycle demonstration</p>
                        </div>
                    </li>
                    <li>
                        <span class="demo-icon">üìä</span>
                        <div>
                            <strong>Performance Metrics</strong>
                            <p>Live velocity, position, and success rate data</p>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </section>

    <!-- Future Scope -->
    <section id="reflection" class="section section-alt">
        <div class="container">
            <div class="section-header">
                <span class="section-tag">Looking Forward</span>
                <h2 class="section-title">Reflection & Future Scope</h2>
            </div>
    
            <div class="reflection-content">
                <!-- Key Learnings -->
                <div class="reflection-block">
                    <h3 class="reflection-subtitle">
                        Key Reflections
                    </h3>
                    <div class="reflection-text">
                        <p>
                            Through this project, we discovered several important insights about learning dynamic manipulation tasks. First, <strong>trajectory complexity doesn't always improve performance</strong> - our 2-knot controller achieved the best throwing distance and velocity, suggesting that simpler action spaces can be easier to optimize. However, the 6-knot controller showed better success rates, indicating a trade-off between peak performance and consistency.
                        </p>
                        <p>
                            We also learned that <strong>reward function design is critical</strong>. Our velocity-weighted reward successfully encouraged the RL agent to discover "physics hacking" behaviors - aggressive joint movements that maximized release velocity beyond what human-intuitive motions would produce. The adaptive catching system highlighted the importance of <strong>robustness to variation</strong>: by dynamically computing catch planes based on observed trajectories rather than fixed positions, the catcher could handle both naive and learned throws effectively.
                        </p>
                        <p>
                            Finally, <strong>simulation-reality gap considerations</strong> became apparent. While our learned policies work well in simulation, the aggressive motions and precise timing would probably face challenges on real hardware due to joint limits, motor dynamics, and sensor noise. 
                        </p>
                    </div>
                </div>
    
                <!-- Challenges Overcome -->
                <div class="reflection-block">
                    <h3 class="reflection-subtitle">
                        Challenges
                    </h3>
                    <div class="reflection-text">
                        <ul class="challenge-list">
                            <li>
                                <strong>Gripper Timing Synching:</strong> Initially, we used fixed timing for gripper release, 
                                leading to inconsistent catches especially in the learned throw. 
                                To fix this, we dynamically computed every timestep using the block's smoothed velocity, predicted intercept time, 
                                and the distance to the end effector. With this, once the block is close enough to the gripper, it closes.
                            </li>
                            <li>
                                <strong>Aaron Challenge:</strong> 
                            </li>
                        </ul>
                    </div>
                </div>
    
                <!-- Future Directions -->
                <div class="reflection-block">
                    <h3 class="reflection-subtitle">
                        Future Work & Extensions
                    </h3>
                    <div class="reflection-text">
                        <h4>Short-term Improvements</h4>
                        <ul class="future-list">
                            <li>
                                <strong>Enhanced Catching Strategies:</strong> Instead of just blocking, implement true catching where the gripper moves with the block to absorb impact, reducing forces and improving reliability. This would require modeling gripper-block contact dynamics.
                            </li>
                            <li>
                                <strong>Visual Perception:</strong> Replace perfect state information from simulation with camera-based tracking. Use computer vision (e.g., YOLO for detection, Kalman filtering for prediction) to estimate block pose and velocity in real-time.
                            </li>
                        </ul>
    
                        <h4>Long-term Directions</h4>
                        <ul class="future-list">
                            <li>
                                <strong>Variable Object Properties:</strong> Generalize to objects with different masses, shapes, and aerodynamic properties. This would require learning object-specific throwing strategies or meta-learning approaches.
                            </li>
                            <li>
                                <strong>Clutter and Obstacles:</strong> Add environmental complexity with obstacles between thrower and catcher, requiring trajectory planning that considers occlusion and collision avoidance.
                            </li>
                            <li>
                                <strong>Human Thrower + Robot Arm:</strong> Instead of two robot arms, have a human throw the object and the robot "catch" it. This would involve learning to predict human throwing styles and adapting catching strategies accordingly.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Team Section -->
    <section id="team" class="section">
        <div class="container">
            <div class="section-header">
                <span class="section-tag">Contributors</span>
                <h2 class="section-title">Team</h2>
                <p class="section-description">
                    CS 639: Robot Learning - Final Project Team
                </p>
            </div>

            <div class="team-grid">
                <!-- Add your team members here -->
                <div class="team-card">
                    <div class="team-avatar">
                        <img src="assets/aaron_headshot.jpeg" alt="Aaron Yuan" class="avatar-img" />
                    </div>
                    <h3>Aaron Yuan</h3>
                    <div class="team-links">
                        <a href="https://www.linkedin.com/in/aaronyuan03/" target="_blank" title="LinkedIn">
                            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                                <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                            </svg>
                        </a>
                    </div>
                </div>

                <div class="team-card">
                    <div class="team-avatar">
                        <img src="assets/felix_headshot.jpeg" alt="Felix Zhu" class="avatar-img" />
                    </div>
                    <h3>Felix Zhu</h3>
                    <div class="team-links">
                        <a href="https://www.linkedin.com/in/felixzhu0" target="_blank" title="LinkedIn">
                            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                                <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                            </svg>
                        </a>
                    </div>
                </div>
            </div>

            <div class="acknowledgments">
                <h3>Acknowledgments</h3>
                <p>This project was completed as part of CS 639: Intro to Robotic Systems final project. Thank you to Mike Hagenow!</p>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-brand">
                    <span class="brand-icon">ü§ñ</span>
                    <span>Robot Throwing & "Catching"</span>
                </div>
                <div class="footer-links">
                    <a href="https://github.com/ayuan1114/robo-final-proj" target="_blank">GitHub Repository</a>
                    <a href="#overview">Documentation</a>
                    <a href="#results">Results</a>
                </div>
            </div>
            <div class="footer-bottom">
                <p>&copy; 2025 CS 639 Final Project. Built with a ‚ù§Ô∏è for Robotic Systems.</p>
            </div>
        </div>
    </footer>

    <script src="js/script.js"></script>
</body>
</html>

